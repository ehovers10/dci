---
title: Bratman et al. on plans
references: ""
---

Plans are a form of commitment regarding future action. We understand the nature of plans in terms of the role that they play in an agent's attempts to successfully navigate the world -- their efforts at *practical reasoning*.

In circumstances calling for action, agents are faced with choice sets, which are just the alternative actions available to the agent. The purpose of practical reasoning is to select, amongst the alternatives in a choice set, that action that best helps the agent meet their goals. In essence, practical reasoning can be represented as a function that takes a *choice set* and a *goals set* and outputs a *preference ordering* over the choice set. There may be applications in which the entire ordering is important, but in general the practical reasoning output is put to use by the agent acting on the top ranked option.

My concern here is with the *choice set* side of the practical reasoning formula. In order to pick the preferred action from within a choice set, one must first have a means of determining its membership.

As understood here, choice sets are non-maximal sets of incompatible actions. Choice sets are restricted to incompatible elements, in the sense that the agent's choice to perform one action precludes his ability to perform any other in the set, because we want to focus only on forced choices. If the options before the agent do not preclude each other, then there is little sense to be made of the claim that the end result of any deliberation over that set is more rational than the other.

Their non-maximality is due to the cognitive and practical limitations of human actors. Perhaps ideal reasoners could engage in practical reasoning by selecting one action from amongst all possibilities full stop. But human reasoners surely do not do this, nor does it seem appropriate to contend that they ought to. The decision process takes both time and cognitive resources. If agents are to avoid paralysis, they must have a means of distributing these resources over a mere handful of options. Additionally, agents come to the decision table with certain conceptual proclivities and limitations. Certain actions that may in principle serve to achieve their goals will simply not be genuine options for them. Blindness to certain options may arise due to the agent's evolutionary and social history. We do not want to say that agents who cannot assess their prospects for action with complete accuracy are precluded from engaging in proper practical reasoning.

I will not attempt to provide a theory of how human agents solve the problem of honing choice sets generally, but I think we can mention a couple broad categories of factors that enter into their determination. There are such factors as the evolutionary and social history of the agent. In a very real sense, our upbringing influences our decision making process both in how we assess the relative merits of the options before us and in what we take to be the genuine options. To take a familiar example, in deliberating on what to eat, my choice set may be limited to pizza or salad. The exclusion of fried salamander need not be because it is in principle unavailable as an option; it just so happens that such a consideration never even enters into the mix. And this need not indicate a failure of rationality on my part; it is simply the result of a-rational processes of choice limitation deriving from my causal heritage.

There are similar factors in play that have less far reaching causal histories. Certain features of my circumstances may make it such that I don't percieve the viability of plausible options. Because these limitations imposed on choice sets derive from a-rational/non-cognitive features of the agent's circumstance, let's label them *saliency restrictions*. They are in essence the factors that determine a choice as a *live option* in William James' sense.

The arational character of saliency conditions means they lack normativity. They involve evolutionarily and socially instilled blinders that guide choice restriction without appeal to rational choice by the agent. However, there is an important sense in which there are certain options that an agent *should* consider. If salience were the sole mechanism by which choice sets were determined, then agents could simplify their decision making without fault simply by responding to situations dogmatically. While it is likely that salience plays some role in the choice set determination phase, if this phase is genuinely an element of practical reason, then salience cannot be the whole story.

A second category of factors that plausibly limit the options in choice sets are more cognitive in nature. It is frequently the case that certain possibilities are simply irrelevant to the circumstances of the agent. Relevance is a tricky notion, but a suitable definition for our purposes can be adapted from the definition of p-dependence offered by John Hawthorne and Jason Stanley {% cite hawthorne2008 | pages: 580 %}:

> Let us say that a choice between options x1...xn is *p dependent* iff the most preferable of x1...xn conditional on the proposition that p is not the same as the most preferable of x1...xn conditional on the proposition that non-p.
Hawthorne and Stanley are concerned with the use of propositions as considerations in the process of selecting an element from a choice set, as opposed to granting initial membership in the choice set. But the insight is apt for our problem as well. The basic thought is that relevance is a matter of impacting one's circumstances. If adding an option to a choice set does not redistribute the preference ordering over the other options, then it is not a relevant option. In large part, whether performance of an action alters one's preference ordering depends on their interests, or goals, in those circumstances. Thus, in addition to performing a selective task, the goal set also ha a hand in dertermining the membersheip fo the choice set that it selects from.

An agent's interests contribute to their choice set determination by filtering out the actions that do not serve their purposes, and salience further hones the options by eliminating the possibilities that are not feasible for the agent given her background. But even after the contribution of these factors, we may be left with a relatively large array of options. What is even worse for effective decision making, agents are constantly beset with changing options. Even when we aren't being fickle about our interests, the environment constantly impinges on us in unexpected ways. To deal with this fact, rational agents form *plans*. Planning serves the project of effective decision making in a number of ways. Formost among those is its ability to provide a stable background against the ever changing environment. When we form plans, we establish certain checkpoints on the way to our goals as fixed, and we adjust our choices to align with those fixed points as much as possible.

In setting plans into action, the agent takes certain future actions to be given, thus constraining the alternatives the agent must take into consideration as time progresses. This establishes stability, which contributes to decision making success. But rigidity, in the form of overly determinate or immutable plans must be avoided. As Bratman et al. put it {% cite bratman1988 | pages: 9-10 | noname %}:

> Given the requirement of stability, plans should also be partial. In addition to bounded computational resources, agents have bounded knowledge. They are neither prescient nor omniscient: the world may change around them in ways they are not in a position to anticipate. Hence highly detailed plans about the far future will often be of little use, the details not worth worrying about.

*Partiality* guarantees for stability by allowing the agent to fill in the details when they become pertinent. My plan to buy lunch from a sandwich shop on the way into the office fails to factor in my means of paying for lunch. If I happen to spend all my cash the night before, my decision making is not derailed because I can still stick to the plan by paying for lunch with a credit card the next morning. A level of open-endedness allows the plan to remain relatively intact even in the face of unanticipated change. Then, at the time of action, standing plans serve to filter out certain alternatives. If an alternative action is incompatible with the outline of the plan, then it is ignored.

Thus, in combination with salience and interests, plans complete the winnowing of options required for agents to effectively use their resources in deliberation. However, the knowledge limitations that make stability so crucial also put limitations on the advisability of steadfast adherence to plans. Again, Bratman et al {% cite bratman1988 | pages: 15 %}:

> A rational agent's current plans must not have irrevocable control over her future deliberation and behavior. Rather a rational agent should sometimes be willing to reconsider her plans in light of unanticipated events. There thus exists a tension between the stability that plans must exhibit to play their role in focusing practical reasoning and the recovability that must also be inherent in them, given that they are formed on the basis of incomplete information about the future.

To accommodate revocability, agents utilize a *filter override mechanism*. In rational agents, this mechanism is sensitive enough to trigger when plans need to be reconsidered without being so sensitive as to undermine the stability that plans provide.

Inquiry is a process of practical reasoning. The choice set is populated with propositions, and the goal set is, at least, to believe the truth. Inquiry realizes the mechanism by which the selection of a preferred proposition is made. As such, effective inquiry requires determination of the membership of the choice set. In virtue of the dilated process of rational inquiry, *plans of inquiry* are an essential element of the representation of the inquiry.
